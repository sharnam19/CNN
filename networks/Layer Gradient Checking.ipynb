{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from layers.util.layer import *\n",
    "from layers.util.util import *\n",
    "from layers.util.activations import *\n",
    "from layers.util.normalization import *\n",
    "from layers.util.convolution import *\n",
    "from layers.util.sequential import *\n",
    "from layers.util.loss import *\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 5.00075339763e-13\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(3,5,5)\n",
    "dOut = np.random.rand(3,5,5)\n",
    "\n",
    "f,cache = relu_forward(x)\n",
    "dx = relu_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:relu_forward(x)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 1.92181772144e-11\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,8)\n",
    "dOut = np.random.rand(5,8)\n",
    "\n",
    "f,cache = sigmoid_forward(x)\n",
    "dx = sigmoid_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:sigmoid_forward(x)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 2.91515393342e-11\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(12,89)\n",
    "dOut = np.random.rand(12,89)\n",
    "\n",
    "f,cache = tanh_forward(x)\n",
    "dx = tanh_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:tanh_forward(x)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky Relu Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 6.43887848045e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(0,1,(5,16))\n",
    "dOut = np.random.normal(0,2,(5,16))\n",
    "\n",
    "f,cache = leaky_relu_forward(x)\n",
    "dx = leaky_relu_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:leaky_relu_forward(x)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(25,42)\n",
    "gamma = np.random.rand(42)\n",
    "beta = np.random.rand(42)\n",
    "dOut = np.random.rand(25,42)\n",
    "params = {}\n",
    "params[\"mode\"]=\"train\"\n",
    "params[\"running_mean\"]=0.5\n",
    "params[\"running_var\"] = 0.04\n",
    "params[\"momentum\"]=0.9\n",
    "params[\"eps\"]=1e-8\n",
    "out,cache = batch_normalization_forward(x,gamma,beta,params)\n",
    "dx,dgamma,dbeta = batch_normalization_backward(dOut,cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 1.27363701366e-07\n",
      "dgamma : 5.96461613783e-11\n",
      "dbeta : 1.93695176604e-12\n"
     ]
    }
   ],
   "source": [
    "dx_num = num_gradient_array(lambda x:batch_normalization_forward(x,gamma,beta,params)[0],x,dOut)\n",
    "dgamma_num = num_gradient_array(lambda gamma:batch_normalization_forward(x,gamma,beta,params)[0],gamma,dOut)\n",
    "dbeta_num = num_gradient_array(lambda beta:batch_normalization_forward(x,gamma,beta,params)[0],beta,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))\n",
    "print(\"dgamma : \"+str(rel_error(dgamma,dgamma_num)))\n",
    "print(\"dbeta : \"+str(rel_error(dbeta,dbeta_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 2.20348552171e-05\n",
      "dgamma : 8.46746396696e-12\n",
      "dbeta : 7.77020220547e-13\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(20,3,10,10)\n",
    "dOut = np.random.rand(20,3,10,10)\n",
    "gamma = np.random.rand(3)\n",
    "beta = np.random.rand(3)\n",
    "params = {}\n",
    "params[\"mode\"]=\"train\"\n",
    "params[\"running_mean\"]=0.5\n",
    "params[\"running_var\"] = 0.04\n",
    "params[\"momentum\"]=0.9\n",
    "params[\"eps\"]=1e-8\n",
    "f,cache= spatial_batch_forward(x,gamma,beta,params)\n",
    "dx,dgamma,dbeta = spatial_batch_backward(dOut,cache)\n",
    "\n",
    "dx_num = num_gradient_array(lambda x:spatial_batch_forward(x,gamma,beta,params)[0],x,dOut)\n",
    "dgamma_num = num_gradient_array(lambda gamma:spatial_batch_forward(x,gamma,beta,params)[0],gamma,dOut)\n",
    "dbeta_num = num_gradient_array(lambda beta:spatial_batch_forward(x,gamma,beta,params)[0],beta,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))\n",
    "print(\"dgamma : \"+str(rel_error(dgamma,dgamma_num)))\n",
    "print(\"dbeta : \"+str(rel_error(dbeta,dbeta_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pooling Gradient Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 5.0007987267e-13\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,6,8,8)\n",
    "dOut= np.random.rand(5,6,4,4)\n",
    "pooling_params={}\n",
    "pooling_params['pooling_height'] = 2\n",
    "pooling_params['pooling_width'] = 2\n",
    "pooling_params['pooling_stride_height'] = 2\n",
    "pooling_params['pooling_stride_width'] = 2\n",
    "\n",
    "f,cache = max_pooling_forward(x,pooling_params)\n",
    "dx = max_pooling_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:max_pooling_forward(x,pooling_params)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Convolution Forward Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f : 2.83041586081e-15\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,3,20,20)\n",
    "w = np.random.rand(10,3,3,3)\n",
    "b = np.random.rand(10)\n",
    "dOut = np.random.rand(5,10,18,18)\n",
    "S = 1\n",
    "params = {}\n",
    "params['stride']=S\n",
    "f,cache = convolve_forward_naive(x,w,b,params)\n",
    "f2,cache2 = convolve_forward_fast(x,w,b,params)\n",
    "print(\"f : \"+str(rel_error(f,f2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Convolution Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 2.30624570369e-08\n",
      "dw : 4.71954228593e-11\n",
      "db : 5.73950193626e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,3,20,20)\n",
    "w = np.random.rand(10,3,3,3)\n",
    "b = np.random.rand(10)\n",
    "dOut = np.random.rand(5,10,18,18)\n",
    "S = 1\n",
    "params = {}\n",
    "params['stride']=S\n",
    "f,cache = convolve_forward_fast(x,w,b,params)\n",
    "dx,dw,db = convolve_backward_fast(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:convolve_forward_fast(x,w,b,params)[0],x,dOut)\n",
    "dw_num = num_gradient_array(lambda w:convolve_forward_fast(x,w,b,params)[0],w,dOut)\n",
    "db_num = num_gradient_array(lambda b:convolve_forward_fast(x,w,b,params)[0],b,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))\n",
    "print(\"dw : \"+str(rel_error(dw,dw_num)))\n",
    "print(\"db : \"+str(rel_error(db,db_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN Gradient Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error: 6.29242142647e-09\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.2, 0.4, num=H)\n",
    "\n",
    "next_h, cache = rnn_step(x, prev_h, Wx, Wh, b)\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print('next_h error: '+str(rel_error(expected_next_h, next_h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error: 1.71420924391e-10\n",
      "dprev_h error: 1.91864481282e-10\n",
      "dWx error: 2.27069552351e-09\n",
      "dWh error: 4.19612725856e-10\n",
      "db error: 3.45571597805e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H = 4, 5, 8\n",
    "x = np.random.randn(N, D)\n",
    "h = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_step(x, h, Wx, Wh, b)\n",
    "\n",
    "dnext_h = np.random.rand(*out.shape)\n",
    "\n",
    "fx = lambda x: rnn_step(x, h, Wx, Wh, b)[0]\n",
    "fh = lambda prev_h: rnn_step(x, h, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_step(x, h, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_step(x, h, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_step(x, h, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = num_gradient_array(fx, x, dnext_h)\n",
    "dprev_h_num = num_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = num_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = num_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = num_gradient_array(fb, b, dnext_h)\n",
    "\n",
    "dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)\n",
    "\n",
    "print('dx error: ' +str(rel_error(dx_num, dx)))\n",
    "print('dprev_h error: '+str(rel_error(dprev_h_num, dprev_h)))\n",
    "print('dWx error: '+str(rel_error(dWx_num, dWx)))\n",
    "print('dWh error: '+ str(rel_error(dWh_num, dWh)))\n",
    "print('db error: '+str(rel_error(db_num, db)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error: 7.72846615831e-08\n"
     ]
    }
   ],
   "source": [
    "N, T, D, H = 2, 3, 4, 5\n",
    "\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N,T,D)\n",
    "h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.7, 0.1, num=H)\n",
    "\n",
    "h, _ = rnn_forward(x, h0, Wx, Wh, b)\n",
    "expected_h = np.asarray([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "print('h error: '+str(rel_error(expected_h, h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error: 1.54084107655e-09\n",
      "dh0 error: 3.38254104079e-09\n",
      "dWx error: 7.0801428247e-09\n",
      "dWh error: 1.30334519893e-07\n",
      "db error: 1.79334265024e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = num_gradient_array(fx, x, dout)\n",
    "dh0_num = num_gradient_array(fh0, h0, dout)\n",
    "dWx_num = num_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = num_gradient_array(fWh, Wh, dout)\n",
    "db_num = num_gradient_array(fb, b, dout)\n",
    "\n",
    "print('dx error: '+ str(rel_error(dx_num, dx)))\n",
    "print('dh0 error: '+ str(rel_error(dh0_num, dh0)))\n",
    "print('dWx error: '+ str(rel_error(dWx_num, dWx)))\n",
    "print('dWh error: '+ str(rel_error(dWh_num, dWh)))\n",
    "print('db error: '+ str(rel_error(db_num, db)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(2,4)\n",
    "w = np.random.rand(4,8)\n",
    "b = np.random.rand(8)\n",
    "dOut = np.random.rand(2,8)\n",
    "out,cache = affine_forward(x,w,b)\n",
    "dx,dw,db = affine_backward(dOut,cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 5.87193401642e-12\n",
      "dw : 1.08361476362e-11\n",
      "db : 7.82655511997e-12\n"
     ]
    }
   ],
   "source": [
    "dx_num = num_gradient_array(lambda x:affine_forward(x,w,b)[0],x,dOut)\n",
    "dw_num = num_gradient_array(lambda w:affine_forward(x,w,b)[0],w,dOut)\n",
    "db_num = num_gradient_array(lambda b:affine_forward(x,w,b)[0],b,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))\n",
    "print(\"dw : \"+str(rel_error(dw,dw_num)))\n",
    "print(\"db : \"+str(rel_error(db,db_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Gradient Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx : 5.00084761089e-13\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,2,6,7,8)\n",
    "dOut= np.random.rand(5,2*6*7*8)\n",
    "\n",
    "f,cache = flatten_forward(x)\n",
    "dx = flatten_backward(dOut,cache)\n",
    "dx_num = num_gradient_array(lambda x:flatten_forward(x)[0],x,dOut)\n",
    "print(\"dx : \"+str(rel_error(dx,dx_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.35266623821\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(20,10)\n",
    "y = np.random.randint(0,10,20)\n",
    "score,loss,dx = softmax_loss(x,y)\n",
    "print(\"Loss: \"+str(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.892562854184\n"
     ]
    }
   ],
   "source": [
    "#x = np.random.rand(20,10)\n",
    "x = np.random.normal(0.1,0.08,(20,10))\n",
    "y = np.random.randint(0,10,20)\n",
    "score,loss, dx = svm_loss(x,y)\n",
    "print(\"Loss: \"+str(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.295085120032\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(0.1,0.5,(20,1))\n",
    "y = np.random.normal(0.1,0.5,(20,))\n",
    "scores, loss, dx = mse_loss(x,y)\n",
    "print(\"Loss: \"+str(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.416874593639\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,1)\n",
    "y = np.random.randint(0,2,(5,1))\n",
    "scores, loss, dx = cross_entropy_loss(x,y)\n",
    "print(\"Loss: \"+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = network.network(input_shape=(64,50),update_params={'alpha':1e-3,'epoch':1},initialization=\"xavier2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a.add(\"batch_normalization\",batch_params={'mode':'train','momentum':0.9,'eps':1e-7})\n",
    "a.add(\"sigmoid\")\n",
    "a.add(\"cross_entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost :18.4026225398\n",
      "Initial Accuracy :0.0\n",
      "Cost at Iteration 0 : 18.604074086\n",
      "Accuracy at Iteration 0 : 0.0\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(64,50)\n",
    "y = np.random.randint(0,2,(64,50))\n",
    "#print(y)\n",
    "#print(x)\n",
    "a.train(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
